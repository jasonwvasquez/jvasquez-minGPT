{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from mingpt.model import GPT\n",
    "from mingpt.utils import set_seed\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset\n",
    "set_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset = load_dataset(\"togethercomputer/RedPajama-Data-1T-Sample\", 'plain_text', streaming=True)\n",
    "dataset = dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"\\\\section{Introduction}\\n\\\\label{sec:intro}\\n\\n\\\\emph{Gender diversity}, or more often its lack thereof, among participants to\\nsoftware development activities has been thoroughly studied in recent years. In\\nparticular, the presence of, effects of, and countermeasures for \\\\emph{gender\\n  bias} in Free/Open Source Software (FOSS) have received a lot of attention\\nover the past decade~\\\\cite{david2008fossdevs, qiu2010kdewomen,\\n  nafus2012patches, kuechler2012genderfoss, vasilescu2014gender,\\n  oneil2016debiansurvey, robles2016womeninfoss, terrell2017gender,\\n  zacchiroli2021gender}.  \\\\emph{Geographic diversity} is on the other hand the\\nkind of diversity that stems from participants in some global activity coming\\nfrom different world regions and cultures.\\n\\nGeographic diversity in FOSS has received relatively little attention in scholarly\\nworks. In particular, while seminal survey-based and\\npoint-in-time medium-scale studies of the geographic origins of FOSS\\ncontributors exist~\\\\cite{ghosh2005understanding, david2008fossdevs,\\n  barahona2008geodiversity, takhteyev2010ossgeography, robles2014surveydataset,\\n  wachs2021ossgeography}, large-scale longitudinal studies of the geographic\\norigin of FOSS contributors are still lacking. Such a quantitative\\ncharacterization would be useful to inform decisions related to global\\ndevelopment teams~\\\\cite{herbsleb2007globalsweng} and hiring strategies in the\\ninformation technology (IT) market, as well as contribute factual information\\nto the debates on the economic impact and sociology of FOSS around the world.\\n\\n\\n\\\\paragraph{Contributions}\\n\\nWith this work we contribute to close this gap by conducting \\\\textbf{the first\\n  longitudinal study of the geographic origin of contributors to public code\\n  over 50 years.} Specifically, we provide a preliminary answer to the\\nfollowing research question:\\n\\\\begin{researchquestion}\\n  From which world regions do authors of publicly available commits come from\\n  and how has it changed over the past 50 years?\\n  \\\\label{rq:geodiversity}\\n\\\\end{researchquestion}\\nWe use as dataset the \\\\SWH/ archive~\\\\cite{swhipres2017} and analyze from it\\n2.2 billion\\\\xspace commits archived from 160 million\\\\xspace projects and authored by\\n43 million\\\\xspace authors during the 1971--2021 time period. \\nWe geolocate developers to\\n\\\\DATAWorldRegions/ world regions, using as signals email country code top-level domains (ccTLDs) and \\nauthor (first/last) names compared with name distributions around the world, and UTC offsets \\nmined from commit metadata.\\n\\nWe find evidence of the early dominance of North America in open source\\nsoftware, later joined by Europe. After that period, the geographic diversity \\nin public code has been constantly increasing.\\nWe also identify relevant historical shifts\\nrelated to the end of the UNIX wars and the increase of coding literacy in\\nCentral and South Asia, as well as of broader phenomena like colonialism and\\npeople movement across countries (immigration/emigration).\\n\\n\\n\\n\\n\\\\paragraph{Data availability.}\\n\\nA replication package for this paper is available from Zenodo at\\n\\\\url{https://doi.org/10.5281/zenodo.6390355}~\\\\cite{replication-package}.\\n\\n\\n \\\\section{Related Work}\\n\\\\label{sec:related}\\n\\nBoth early and recent works~\\\\cite{ghosh2005understanding, david2008fossdevs,\\n  robles2014surveydataset, oneil2016debiansurvey} have characterized the\\ngeography of Free/Open Source Software (FOSS) using \\\\emph{developer surveys},\\nwhich provide high-quality answers but are limited in size (2-5\\\\,K developers)\\nand can be biased by participant sampling.\\n\\nIn 2008 Barahona et al.~\\\\cite{barahona2008geodiversity} conducted a seminal\\nlarge-scale (for the time) study on FOSS \\\\emph{geography using mining software\\n  repositories (MSR) techniques}. They analyzed the origin of 1\\\\,M contributors\\nusing the SourceForge user database and mailing list archives over the\\n1999--2005 period, using as signals information similar to ours: email domains\\nand UTC offsets. \\nThe studied period (7 years) in~\\\\cite{barahona2008geodiversity} is shorter than \\nwhat is studied in the present paper (50 years) and the data sources are \\nlargely different; with that in mind, our results show a slightly larger quote of \\nEuropean v.~North American contributions.\\n\\nAnother empirical work from 2010 by Takhteyev and\\nHilts~\\\\cite{takhteyev2010ossgeography} harvested self-declared geographic\\nlocations of GitHub accounts recursively following their connections,\\ncollecting information for $\\\\approx$\\\\,70\\\\,K GitHub users.  A very recent\\nwork~\\\\cite{wachs2021ossgeography} by Wachs et al.~has geolocated half a million\\nGitHub users, having contributed at least 100 commits each, and who\\nself-declare locations on their GitHub profiles. While the study is\\npoint-in-time as of 2021, the authors compare their findings\\nagainst~\\\\cite{barahona2008geodiversity, takhteyev2010ossgeography} to\\ncharacterize the evolution of FOSS geography over the time snapshots taken by\\nthe three studies.\\n\\nCompared with previous empirical works, our study is much larger scale---having\\nanalyzed 43 million\\\\xspace authors of 2.2 billion\\\\xspace commits from 160 million\\\\xspace\\nprojects---longitudinal over 50 years of public code contributions rather than\\npoint in time, and also more fine-grained (with year-by-year granularity over\\nthe observed period). Methodologically, our study relies on Version Control\\nSystem (VCS) commit data rather than platform-declared location information.\\n\\n\\nOther works---in particular the work by Daniel~\\\\cite{daniel2013ossdiversity}\\nand, more recently, Rastogi et al.~\\\\cite{rastogi2016geobias,\\n  rastogi2018geobias, prana2021geogenderdiversity}---have studied geographic\\n\\\\emph{diversity and bias}, i.e., the extent to which the origin of FOSS\\ndevelopers affect their collaborative coding activities.\\nIn this work we characterized geographic diversity in public code for the first\\ntime at this scale, both in terms of contributors and observation period. We do\\nnot tackle the bias angle, but provide empirical data and findings that can be\\nleveraged to that end as future work.\\n\\n\\\\emph{Global software engineering}~\\\\cite{herbsleb2007globalsweng} is the\\nsub-field of software engineering that has analyzed the challenges of scaling\\ndeveloper collaboration globally, including the specific concern of how to deal\\nwith geographic diversity~\\\\cite{holmstrom2006globaldev, fraser2014eastwest}.\\nDecades later the present study provides evidence that can be used, in the\\nspecific case of public code and at a very large scale, to verify which\\npromises of global software engineering have borne fruit.\\n\\n\\n\\n\\n\\n\\n \\\\section{Methodology}\\n\\\\label{sec:method}\\n\\n\\n\\\\newif\\\\ifgrowthfig  \\\\growthfigtrue\\n\\\\ifgrowthfig\\n\\\\begin{figure}\\n  \\\\includegraphics[width=\\\\columnwidth]{yearly-commits}\\n  \\\\caption{Yearly public commits over time (log scale).\\n}\\n  \\\\label{fig:growth}\\n\\\\end{figure}\\n\\\\fi\\n\\n\\\\paragraph{Dataset}\\n\\nWe retrieved from \\\\SWH/~\\\\cite{swh-msr2019-dataset} all commits archived until \\\\DATALastCommitDate/.\\nThey amount to \\\\DATACommitsRaw/ commits, unique by SHA1 identifier, harvested from \\\\DATATotalCommitsInSH/ public projects coming from major development forges (GitHub, GitLab, etc.) and package repositories (Debian, PyPI, NPM, etc.).\\nCommits in the dataset are by \\\\DATAAuthorsRaw/ authors, unique by $\\\\langle$name, email$\\\\rangle$ pairs.\\nThe dataset came as two relational tables, one for commits and one for authors, with the former referencing the latter via a foreign key.\\n\\\\iflong\\nEach row in the commit table contains the following fields: commit SHA1 identifier, author and committer timestamps, author and committer identifiers (referencing the author table).\\nThe distinction between commit authors and committers come from Git, which allows to commit a change authored by someone else.\\nFor this study we focused on authors and ignored committers, as the difference between the two is not relevant for our research questions and the amount of commits with a committer other than its author is negligible.\\n\\\\fi\\nFor each entry in the author table we have author full name and email as two separate strings of raw bytes.\\n\\nWe removed implausible or unusable names that: are not decodable as UTF-8 (\\\\DATAAuthorsRmNondecodable/ author names removed), are email addresses instead of names (\\\\DATAAuthorsRmEmail/ ``names''), consist of only blank characters (\\\\DATAAuthorsRmBlank/), contain more than 10\\\\% non-letters (\\\\DATAAuthorsRmNonletter/), are longer than 100 characters (\\\\DATAAuthorsRmToolong/).\\nAfter filtering, about \\\\DATAAuthorsPlausibleApprox/ authors (\\\\DATAAuthorsPlausiblePct/ of the initial dataset) remained for further analysis.\\n\\nNote that the amount of public code commits (and authors) contained in the\\ninitial dataset grows exponentially over\\ntime~\\\\cite{swh-provenance-emse}\\\\ifgrowthfig, as shown for commits in\\n\\\\Cref{fig:growth}\\\\else: from $10^4$ commits in 1971, to $10^6$ in 1998, to\\nalmost $10^9$ in 2020\\\\fi. As a consequence the observed trends tend to be more\\nstable in recent decades than in 40+ year-old ones, due to statistics taken on\\nexponentially larger populations.\\n\\n\\n\\\\paragraph{Geolocation}\\n\\n\\\\begin{figure}\\n  \\\\centering\\n  \\\\includegraphics[clip,trim=6cm 6cm 0 0,width=\\\\linewidth]{subregions-ours}\\n  \\\\caption{The \\\\DATAWorldRegions/ world regions used as geolocation targets.}\\n  \\\\label{fig:worldmap}\\n\\\\end{figure}\\n\\nAs geolocation targets we use macro world regions derived from the United Nations geoscheme~\\\\cite{un1999geoscheme}.\\nTo avoid domination by large countries (e.g., China or Russia) within macro regions, we merged and split some regions based on geographic proximity and the sharing of preeminent cultural identification features, such as spoken language.\\n\\\\Cref{fig:worldmap} shows the final list of \\\\DATAWorldRegions/ world regions used as geolocation targets in this study.\\n\\nGeolocation of commit authors to world regions uses the two complementary techniques introduced in~\\\\cite{icse-seis-2022-gender}, briefly recalled below.\\nThe first one relies on the country code top-level domain (ccTLD) of email addresses extracted from commit metadata, e.g., \\\\texttt{.fr}, \\\\texttt{.ru}, \\\\texttt{.cn}, etc.\\nWe started from the IANA list of Latin character ccTLDs~\\\\cite{wikipedia-cctld} and manually mapped each corresponding territory to a target world region.\\n\\nThe second geolocation technique uses the UTC offset of commit timestamps (e.g., UTC-05:00) and author names to determine the most likely world region of the commit author.\\nFor each UTC offset we determine a list of compatible places (country, state, or dependent territory) in the world that, at the time of that commit, had that UTC offset; commit time is key here, as country UTC offsets vary over time due to timezone changes.\\nTo make this determination we use the IANA time zone database~\\\\cite{tzdata}.\\n\\nThen we assign to each place a score that captures the likelihood that a given author name is characteristic of it.\\nTo this end we use the Forebears dataset of the frequencies of the most common first and family names which, quoting from~\\\\cite{forebear-names}: {\\\\itshape ``provides the approximate incidence of forenames and surnames produced from a database of \\\\num{4 044 546 938} people (55.5\\\\% of living people in 2014). As of September 2019 it covers \\\\num{27 662 801} forenames and \\\\num{27 206 821} surnames in 236 jurisdictions.''}\\nAs in our dataset authors are full name strings (rather than split by first/family name), we first tokenize names (by blanks and case changes) and then lookup individual tokens in both first and family names frequency lists.\\nFor each element found in name lists we multiply the place population\\\\footnotemark{} by the name frequency to obtain a measure that is proportional to the number of persons bearing that name (token) in the specific place.\\n\\\\footnotetext{To obtain population totals---as the notion of ``place'' is heterogeneous: full countries v.~slices of large countries spanning multiple timezones---we use a mixture of primary sources (e.g., government websites), and non-primary ones (e.g., Wikipedia articles).}\\nWe sum this figure for all elements to obtain a place score, ending up with a list of $\\\\langle$place, score$\\\\rangle$ pairs.\\nWe then partition this list by the world region that a place belongs to and sum the score for all the places in each region to obtain an overall score, corresponding to the likelihood that the commit belongs to a given world region.\\nWe assign the starting commit as coming from the world region with the highest score.\\n\\nThe email-based technique suffers from the limited and unbalanced use of ccTLDs: most developers use generic TLDs such as \\\\texttt{.com}, \\\\texttt{.org}, or \\\\texttt{.net}.\\nMoreover this does not happen uniformly across zones: US-based developers, for example, use the \\\\texttt{.us} ccTLD much more seldomly than their European counterparts.\\nOn the other hand the offset/name-based technique relies on the UTC offset of the commit timestamps.\\nDue to tool configurations on developer setups, a large number of commits in the dataset has an UTC offset equal to zero.\\nThis affects less recent commits (\\\\DATACommitsTZZTwoThousandTwenty/ of 2020s commits have a zero offset) than older ones (\\\\DATACommitsTZZTwoThousand/ in 2000).\\nAs a result the offset/name-based technique could end up detecting a large share of older commits as authored by African developers, and to a lesser extent Europeans.\\n\\nTo counter these issues we combine the two geolocation techniques together by applying the offset/name-based techniques to all commits with a non-zero UTC offset, and the email-based on to all other commits.\\n\\n\\n \\\\section{Results and Discussion}\\n\\\\label{sec:results}\\n\\n\\\\begin{figure*}\\n  \\\\centering\\n  \\\\includegraphics[width=\\\\linewidth]{stacked.pdf}\\n  \\\\caption{Ratio of commits (above) and active authors (below) by world zone over the 1971--2020 period.}\\n  \\\\Description[Chart]{Stacked bar chart showing the world zone ratios for commits and authors over the 1971--2020 period.}\\n  \\\\label{fig:results}\\n\\\\end{figure*}\\n\\n\\n \\nTo answer \\\\cref{rq:geodiversity} we gathered the number of commits and distinct authors per year and per world zone.\\nWe present the obtained results in \\\\Cref{fig:results} as two stacked bar charts, showing yearly breakdowns for commits and authors respectively.\\nEvery bar represents a year and is partitioned in slices showing the commit/author ratio for each of the world regions of \\\\Cref{fig:worldmap} in that year.\\nTo avoid outliers due to sporadic contributors, in the author chart we only consider authors having contributed at least 5 commits in a given year.\\n\\nWhile observing trends in the charts remember that the total numbers of commits and authors grow exponentially over time.\\nHence for the first years in the charts, the number of data points in some world regions can be extremely small, with negative consequences on the stability of trends.\\n\\n\\n\\n\\n\\\\paragraph{Geographic diversity over time}\\n\\nOverall, the general trend appears to be that the \\\\textbf{geographic diversity in public code is increasing}: North America and Europe alternated their ``dominance'' until the middle of the 90s; from that moment on most other world regions show a slow but steady increment.\\nThis trend of increased participation into public code development includes Central and South Asia (comprising India), Russia, Africa, Central and South America,\\nNotice that also zones that do not seem to follow this trend, such as Australia and New Zealand, are also increasing their participation, but at a lower speed with respect to other zones.\\nFor example, Australia and New Zealand incremented the absolute number of their commits by about 3 orders of magnitude from 2000 to present days.\\n\\nAnother interesting phenomenon that can be appreciated in both charts is the sudden contraction of contributions from North America in 1995; since the charts depict ratios, this corresponds to other zones, and Europe in particular, increasing their share.\\nAn analysis of the main contributions in the years right before the contraction shows that nine out of ten have \\\\texttt{ucbvax.Berkeley.EDU} as author email domain, and the tenth is Keith Bostic, one of the leading Unix BSD developers, appearing with email \\\\texttt{bostic}.\\nNo developer with the same email domain appears anymore within the first hundred contributors in 1996.\\nThis shows the relevance that BSD Unix and the Computer Systems Research Group at the University of California at Berkeley had in the history of open source software.\\nThe group was disbanded in 1995, partially as a consequence of the so-called UNIX wars~\\\\cite{kernighan2019unixhistory}, and this contributes significantly---also because of the relatively low amount of public code circulating at the time---to the sudden drop of contributions from North America in subsequent years.\\nDescendant UNIX operating systems based on BSD, such as OpenBSD, FreeBSD, and NetBSD had smaller relevance to world trends due to (i) the increasing amount of open source code coming from elsewhere and (ii) their more geographically diverse developer community.\\n\\nAnother time frame in which the ratios for Europe and North America are subject to large, sudden changes is 1975--79.\\nA preliminary analysis shows that these ratios are erratic due to the very limited number of commits in those time period, but we were unable to detect a specific root cause.\\nTrends for those years should be subject to further studies, in collaboration with software historians.\\n\\n\\n\\\\paragraph{Colonialism}\\n\\nAnother trend that stands out from the charts is that Africa appears to be well represented.\\nTo assess if this results from a methodological bias, we double-checked the commits detected as originating from Africa for timezones included in the $[0, 3]$ range using both the email- the offset/name-based methods.\\nThe results show that the offset/name-based approach assigns 22.7\\\\% of the commits to Africa whereas the email-based one only assigns 2.7\\\\% of them.\\nWhile a deeper investigation is in order, it is our opinion that the phenomenon we are witnessing here is a consequence of colonialism, specifically the adoption of Europeans names in African countries.\\nFor example the name Eric, derived from Old Norse, is more popular in Ghana than it is in France or in the UK.\\nThis challenges the ability of the offset/name-based method to correctly differentiate between candidate places.\\nTogether with the fact that several African countries are largely populated, the offset/name-based method could detect European names as originating from Africa.\\nWhile this cuts both way, the likelihood of a random person contributing to public code is very different between European countries, all having a well-developed software industry, and African countries that do not all share this trait.\\n\\n\\n\\\\paragraph{Immigration/emigration}\\n\\nAnother area where a similar phenomenon could be at play is the evolution of Central and South America.\\nContribution from this macro region appears to be growing steadily.\\nTo assess if this is the result of a bias introduced by the name-based detection we analyzed the evolution of offset/name-based assignment over time for authors whose email domain is among the top-ten US-based entities in terms of overall contributions (estimated in turn by analyzing the most frequent email domains and manually selecting those belonging to US-based entities).\\nIn 1971 no author with an email from top US-based entities is detected as belonging to Central and South America, whereas in 2019 the ratio is 12\\\\%.\\nNowadays more than one tenth of the people email-associated to top US-based entities have popular Central and South American names, which we posit as a likely consequence of immigration into US (emigration from Central and South America).\\nSince immigration has a much longer history than what we are studying here, what we are witnessing probably includes long-term consequences of it, such as second and third generation immigrants employed in white-collar jobs, such as software development.\\n\\n\\n\\n\\n \\\\section{Limitations and Future Work}\\n\\\\label{sec:conclusion}\\n\\nWe have performed an exploratory, yet very large scale, empirical study of the geographic diversity in public code commits over time.\\nWe have analyzed 2.2 billion\\\\xspace public commits covering the \\\\DATAYearRange/ time period.\\nWe have geolocated developers to \\\\DATAWorldRegions/ world regions using as signals email domains, timezone offsets, and author names.\\nOur findings show that the geographic diversity in public code is increasing over time, and markedly so over the past 20--25 years.\\nObserved trends also co-occur with historical events and macro phenomena like the end of the UNIX wars, increase of coding literacy around the world, colonialism, and immigration.\\n\\n\\n\\\\medskip\\n\\\\emph{Limitations.}\\nThis study relies on a combination of two geolocation methods: one based on email domains, another based on commit UTC offsets and author names.\\nWe discussed some of the limitations of either method in \\\\Cref{sec:method}, motivating our decision of restricting the use of the email-based method to commits with a zero UTC offset.\\nAs a consequence, for most commits in the dataset the offset/name-based method is used.\\nWith such method, the frequencies of forenames and surnames are used to rank candidate zones that have a compatible UTC offset at commit time.\\n\\nA practical consequence of this is that for commits with, say, offset UTC+09:00 the candidate places can be Russia, Japan and Australia, depending on the specific date due to daylight saving time.\\nPopular forenames and surnames in these regions tend to be quite different so the likelihood of the method to provide a reliable detection is high.\\nFor other offsets the set of popular forenames and surnames from candidate zones can exhibit more substantial overlaps, negatively impacting detection accuracy.\\nWe have discussed some of these cases in \\\\Cref{sec:results}, but other might be lingering in the results impacting observed trends.\\n\\nThe choice of using the email-based method for commits with zero UTC offset, and the offset/name-based method elsewhere, has allowed us to study all developers not having a country-specific email domain (ccTLD), but comes with the risk of under-representing the world zones that have (in part and in some times of the year) an actual UTC offset of zero.\\n\\nA potential bias in this study could be introduced by the fact that the name database used for offset/name-based geolocation only contains names formed using Latin alphabet characters.\\nWe looked for names containing Chinese, Japanese, and Korean characters in the original dataset, finding only a negligible amount of authors who use non-Latin characters in their VCS names, which leads us to believe that the impact of this issue is minimal.\\n\\nWe did not apply identity merging (e.g., using state-of-the-art tools like SortingHat~\\\\cite{moreno2019sortinghat}), but we do not expect this to be a significant issue because: (a) to introduce bias in author trends the distribution of identity merges around the world should be uneven, which seems unlikely; and (b) the observed commit trends (which would be unaffected by identity merging) are very similar to observed author trends.\\n\\nWe did not systematically remove known bot accounts~\\\\cite{lebeuf2018swbots} from the author dataset, but we did check for the presence of software bots among the top committers of each year. We only found limited traces of continuous integration (CI) bots, used primarily to automate merge commits. After removing CI bots from the dataset the observed global trends were unchanged, therefore this paper presents unfiltered data.\\n\\n\\n\\\\medskip\\n\\\\emph{Future work.}\\nTo some extent the above limitations are the price to pay to study such a large dataset: there exists a trade-off between large-scale analysis and accuracy.\\nWe plan nonetheless to further investigate and mitigate them in future work.\\nMulti-method approaches, merging data mining with social science methods, could be applied to address some of the questions raised in this exploratory study.\\nWhile they do not scale to the whole dataset, multi-methods can be adopted to dig deeper into specific aspects, specifically those related to social phenomena.\\nSoftware is a social artifact, it is no wonder that aspects related to sociocultural evolution emerge when analyzing its evolution at this scale.\\n\\n\\n\\n\\n \\n\\\\clearpage\\n\\n\\n\",\n",
       " 'meta': \"{'timestamp': '2022-03-30T02:27:00', 'yymm': '2203', 'arxiv_id': '2203.15369', 'language': 'en', 'url': 'https://arxiv.org/abs/2203.15369'}\"}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for the Red Pajama dataset\n",
    "class RedPajamaDataset(Dataset):\n",
    "    def __init__(self, data, max_length=1024):\n",
    "        self.data = data\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "        self.tokenizer.pad_token_id = 50256\n",
    "        self.max_length = max_length\n",
    "        self.vocab_size = self.tokenizer.vocab_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx]['text']\n",
    "        # Tokenize the text\n",
    "        tokens = self.tokenizer.encode(text, add_special_tokens=True, max_length=self.max_length, truncation=True, return_tensors='pt', padding=True)\n",
    "        # Split the tokens into chunks of max_length\n",
    "        # Shift the tokens to get targets (excluding the [CLS] token)\n",
    "        target_tokens = tokens[:, 1:].clone()  # Exclude the [CLS] token\n",
    "        tokens = tokens[:, :-1]  # Exclude the last token to match the shifted targets\n",
    "        \n",
    "        return tokens, target_tokens\n",
    "\n",
    "# Create an instance of the custom dataset\n",
    "# red_pajama_dataset = RedPajamaDataset(dataset)\n",
    "x, y = red_pajama_dataset[0]\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 2.55M\n"
     ]
    }
   ],
   "source": [
    "# create a GPT instance\n",
    "from mingpt.model import GPT\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt-nano'\n",
    "model_config.vocab_size = tokenizer.vocab_size\n",
    "model_config.block_size = 1023\n",
    "model_config.checkpoint = None\n",
    "model = GPT(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cpu\n"
     ]
    }
   ],
   "source": [
    "# create a Trainer object\n",
    "from mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-4 # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 1000 + model.iter_num if model_config.checkpoint else 1000  # This is a change\n",
    "train_config.num_workers = 0\n",
    "train_config.checkpoint_iters = 100     # This is a change\n",
    "train_config.batch_size = 1\n",
    "trainer = Trainer(train_config, model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 0.00ms; iter 0: train loss 10.82837\n",
      "iter_dt 1663.07ms; iter 100: train loss 8.35626\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/jasonvasquez/Desktop/cs_674/minGPT/project2a.ipynb Cell 7\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonvasquez/Desktop/cs_674/minGPT/project2a.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39miter_dt \u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39miter_dt\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m1000\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39mms; iter \u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39miter_num\u001b[39m}\u001b[39;00m\u001b[39m: train loss \u001b[39m\u001b[39m{\u001b[39;00mtrainer\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mitem()\u001b[39m:\u001b[39;00m\u001b[39m.5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jasonvasquez/Desktop/cs_674/minGPT/project2a.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m trainer\u001b[39m.\u001b[39mset_callback(\u001b[39m'\u001b[39m\u001b[39mon_batch_end\u001b[39m\u001b[39m'\u001b[39m, batch_end_callback)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jasonvasquez/Desktop/cs_674/minGPT/project2a.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/Desktop/cs_674/minGPT/mingpt/trainer.py:113\u001b[0m, in \u001b[0;36mTrainer.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m prev_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\n\u001b[1;32m    112\u001b[0m \u001b[39m# forward the model\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m logits, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss \u001b[39m=\u001b[39m model(x, y)\n\u001b[1;32m    115\u001b[0m \u001b[39m# backprop and update the parameters\u001b[39;00m\n\u001b[1;32m    116\u001b[0m model\u001b[39m.\u001b[39mzero_grad(set_to_none\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/cs_674/minGPT/mingpt/model.py:322\u001b[0m, in \u001b[0;36mGPT.forward\u001b[0;34m(self, idx, targets)\u001b[0m\n\u001b[1;32m    320\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    321\u001b[0m \u001b[39mif\u001b[39;00m targets \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 322\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mcross_entropy(\n\u001b[1;32m    323\u001b[0m         logits\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, logits\u001b[39m.\u001b[39;49msize(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)), targets\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m), ignore_index\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    325\u001b[0m \u001b[39mreturn\u001b[39;00m logits, loss\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3026\u001b[0m, in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[0;32m-> 3026\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_C\u001b[39m.\u001b[39;49m_nn\u001b[39m.\u001b[39;49mcross_entropy_loss(\u001b[39minput\u001b[39;49m, target, weight, _Reduction\u001b[39m.\u001b[39;49mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 100 == 0:\n",
    "        print(f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f}\")\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "\n",
    "trainer.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
